{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "import glob\n",
    "from typing import Union\n",
    "from detect_delimiter import detect\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "files_dir = os.path.expanduser('~/static/media/orbit_attitude')\n",
    "saving_path = os.path.expanduser(f'~/static/media/orbit_attitude/merged/{{}}.csv')\n",
    "\n",
    "# files_dir = os.path.expanduser('/mnt/data_products/afr/mission_ops/selected_csvs')\n",
    "# saving_path = os.path.expanduser(f'/mnt/data_products/afr/mission_ops/selected_csvs/merged/{{}}.csv')\n",
    "\n",
    "\n",
    "merged_files_dir = os.path.expanduser('~/static/media/orbit_attitude/merged/')\n",
    "# merged_files_dir = os.path.expanduser('/mnt/data_products/afr/mission_ops/selected_csvs/merged/')\n",
    "os.makedirs(merged_files_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "class FileHandlingMethods:\n",
    "    epoch_end_range = 2077100195000\n",
    "    epoch_start_range = 1685557800000\n",
    "\n",
    "    def __init__(self, working_file_path, working_dataframe):\n",
    "\n",
    "        self.working_file_path = working_file_path\n",
    "        self.working_dataframe = working_dataframe\n",
    "        self.epoch_end_range = 2077100195000\n",
    "        self.epoch_start_range = 1685557800000\n",
    "        if os.path.isfile(self.working_file_path):\n",
    "            with open(self.working_file_path, \"r\") as f:\n",
    "                self.delimiter = detect(f.readline(), whitelist=[',', '|', '\\t', ' ', ':'])\n",
    "            self.working_dataframe = pd.read_csv(self.working_file_path, sep=self.delimiter, skipinitialspace=True,\n",
    "                                                 index_col=False)\n",
    "        else:\n",
    "            self.delimiter = ','\n",
    "            self.working_dataframe = None\n",
    "        if self.working_dataframe is not None:\n",
    "            self.working_dataframe.columns = self.working_dataframe.columns.str.strip()\n",
    "            for column in self.working_dataframe.columns:\n",
    "                if self.working_dataframe[column].dtype == 'str':\n",
    "                    self.working_dataframe[column] = self.working_dataframe[column].str.strip()\n",
    "                elif self.working_dataframe[column].dtype == 'object':\n",
    "                    self.working_dataframe[column] = self.working_dataframe[column].str.strip()\n",
    "            self.epoch_column = self.find_epoch_column()\n",
    "\n",
    "    @staticmethod\n",
    "    def is_epoch(column):\n",
    "        try:\n",
    "            pd.to_datetime(column)\n",
    "            return True\n",
    "        except (ValueError, TypeError):\n",
    "            return False\n",
    "\n",
    "    def find_epoch_column(self) -> str:\n",
    "        col = ''\n",
    "        if self.working_dataframe is not None:\n",
    "            for col in self.working_dataframe.columns:\n",
    "                if pd.api.types.is_numeric_dtype(self.working_dataframe[col].dtype):\n",
    "                    if any(self.working_dataframe[col].apply(self.is_epoch)):\n",
    "                        return col\n",
    "                # else:\n",
    "                #     pass\n",
    "        return col\n",
    "\n",
    "    def handle_any_file(self) -> Union[pd.DataFrame, None]:\n",
    "\n",
    "        if self.working_dataframe is not None:\n",
    "            self.working_dataframe = pd.read_csv(self.working_file_path, sep=self.delimiter, skipinitialspace=True,\n",
    "                                                 index_col=False)\n",
    "            epoch_column = self.find_epoch_column()\n",
    "            # print(epoch_column)\n",
    "            self.working_dataframe.columns = self.working_dataframe.columns.str.strip()\n",
    "            if epoch_column and 'epoch [msec]' not in self.working_dataframe.columns:\n",
    "                self.working_dataframe['epoch [msec]'] = pd.to_numeric(self.working_dataframe[epoch_column],\n",
    "                                                                       errors='coerce')\n",
    "            # print('EPoch Column is existing')\n",
    "        return self.working_dataframe\n",
    "\n",
    "    def handle_acc_ltt(self) -> Union[pd.DataFrame, None]:\n",
    "        if self.working_dataframe is not None:\n",
    "            if self.working_dataframe.empty:\n",
    "                # return messages.warning(request, \"Error: <br> Selected File is Empty\")\n",
    "                warning_msg = \"No working dataframe found.\"\n",
    "                # warnings.warn(warning_msg, UserWarning)\n",
    "                return None\n",
    "        return self.working_dataframe\n",
    "\n",
    "    def handle_acc_ott(self) -> Union[pd.DataFrame, None]:\n",
    "        if self.working_dataframe is not None:\n",
    "            craft_moi = [[3.55597297, -0.07972644, 0.09050089], [-0.07972644, 4.45537057, 0.05467931],\n",
    "                         [0.09050089, 0.05467931, 3.56778807]]\n",
    "            gyro_0, gyro_1, gyro_2 = (\n",
    "                self.working_dataframe['gyro val0 [dps]'], self.working_dataframe['gyro val1 [dps]'],\n",
    "                self.working_dataframe['gyro val2 [dps]'])\n",
    "            rps_0, rps_1, rps_2 = (gyro_0 / 180) * np.pi, (gyro_1 / 180) * np.pi, (gyro_2 / 180) * np.pi\n",
    "            Nms_0, Nms_1, Nms_2 = (craft_moi[0][0] * rps_0) + (craft_moi[0][1] * rps_1) + (\n",
    "                    craft_moi[0][2] * rps_2), (craft_moi[1][0] * rps_0) + (craft_moi[1][1] * rps_1) + (\n",
    "                                          craft_moi[1][2] * rps_2), (craft_moi[2][0] * rps_0) + (\n",
    "                                          craft_moi[2][1] * rps_1) + (craft_moi[2][2] * rps_2)\n",
    "            Angular_Momentum = (np.sqrt(Nms_0 ** 2 + Nms_1 ** 2 + Nms_2 ** 2)) * 1000\n",
    "            self.working_dataframe['Angular_Momentum'] = Angular_Momentum\n",
    "            self.working_dataframe['epoch [msec]'] = pd.to_numeric(self.working_dataframe[self.epoch_column],\n",
    "                                                                   errors='coerce')\n",
    "        return self.working_dataframe\n",
    "\n",
    "    def handle_ppdh_ltt(self) -> Union[pd.DataFrame, None]:\n",
    "        if self.working_dataframe is not None:\n",
    "            self.working_dataframe['epoch [msec]'] = pd.to_numeric(self.working_dataframe[self.epoch_column],\n",
    "                                                                   errors='coerce')\n",
    "        return self.working_dataframe\n",
    "\n",
    "    def handle_pcu_ltt(self) -> Union[pd.DataFrame, None]:\n",
    "        if self.working_dataframe is not None:\n",
    "            self.working_dataframe['epoch [msec]'] = pd.to_numeric(self.working_dataframe[self.epoch_column],\n",
    "                                                                   errors='coerce')\n",
    "        return self.working_dataframe\n",
    "\n",
    "    def handle_obc_ltt(self) -> Union[pd.DataFrame, None]:\n",
    "        if self.working_dataframe is not None:\n",
    "            self.working_dataframe['epoch [msec]'] = pd.to_numeric(self.working_dataframe[self.epoch_column],\n",
    "                                                                   errors='coerce')\n",
    "            # obc_names = ['LTT Timestamp', 'LTT t_epoch [msec]', 'OBC Data Timestamp']\n",
    "            # if ('LTT t_epoch [msec]' in self.working_dataframe.columns) and ~self.working_dataframe[\n",
    "            #         'LTT t_epoch [msec]'].empty:\n",
    "            #     self.working_dataframe['epoch [msec]'] = pd.to_numeric(self.working_dataframe['LTT t_epoch [msec]'],\n",
    "            #                                                            errors='coerce')\n",
    "            #\n",
    "            # elif ('OBC Data Timestamp' in self.working_dataframe.columns) and ~self.working_dataframe[\n",
    "            #     'OBC Data Timestamp'].empty:\n",
    "            #     # print('Epoch column exist')\n",
    "            #     self.working_dataframe['epoch [msec]'] = pd.to_numeric(self.working_dataframe['OBC Data Timestamp'],\n",
    "            #                                                            errors='coerce')\n",
    "        return self.working_dataframe\n",
    "\n",
    "    def handle_gps_ltt(self) -> Union[pd.DataFrame, None]:\n",
    "        if self.working_dataframe is not None:\n",
    "            self.working_dataframe.rename(columns={'Epoch [msec]': 'epoch [msec]'}, inplace=True)\n",
    "            # self.working_dataframe['epoch [msec]'] = pd.to_numeric(self.working_dataframe['OBC Data Timestamp'],\n",
    "            #                                     errors='coerce')\n",
    "        return self.working_dataframe\n",
    "\n",
    "    def handle_registers_values(self) -> Union[list, None]:\n",
    "\n",
    "        reg_columns = []\n",
    "        if self.working_dataframe is not None:\n",
    "            self.working_dataframe = self.working_dataframe[\n",
    "                (self.working_dataframe['epoch [msec]'] < self.epoch_end_range) & (\n",
    "                        self.working_dataframe['epoch [msec]'] > self.epoch_start_range)]\n",
    "            # print(self.working_dataframe['epoch [msec]'])\n",
    "            object_columns = self.working_dataframe.select_dtypes(include=['object']).columns\n",
    "            for column in object_columns:\n",
    "                if self.working_dataframe[column].str.strip().str.startswith('0x').any():\n",
    "                    renamed_column = column.strip()\n",
    "                    # print(renamed_column)\n",
    "                    self.working_dataframe[f'{renamed_column}_integer'] = self.working_dataframe[column].apply(\n",
    "                        lambda x: int(x.replace(' ', '').strip(), 16) if isinstance(x, str) and x.strip().startswith(\n",
    "                            '0x') else x)\n",
    "                    reg_columns.append(f'{renamed_column}_integer')\n",
    "                    del self.working_dataframe[column]\n",
    "                elif self.working_dataframe[column].str.startswith('-').any():\n",
    "                    self.working_dataframe[column].replace('-', np.NaN)\n",
    "                    self.working_dataframe[column] = pd.to_numeric(self.working_dataframe[column], errors='coerce')\n",
    "        return reg_columns\n",
    "\n",
    "    def apply_null_mask(self) -> Union[pd.DataFrame, None]:\n",
    "\n",
    "        result_rows = []\n",
    "        if self.working_dataframe is not None:\n",
    "            self.working_dataframe['UTC_Time'] = pd.to_datetime(\n",
    "                np.clip(self.working_dataframe['epoch [msec]'], np.iinfo(np.int64).min, np.iinfo(np.int64).max),\n",
    "                unit='ms',\n",
    "                errors='coerce'\n",
    "            )\n",
    "            # self.working_dataframe['UTC_Time'] = pd.to_datetime(self.working_dataframe['epoch [msec]'], unit='ms')\n",
    "            self.working_dataframe.sort_values(by='UTC_Time', inplace=True)\n",
    "            self.working_dataframe['time_diff'] = self.working_dataframe['UTC_Time'].diff()\n",
    "            insert_null_mask = self.working_dataframe['time_diff'] > pd.Timedelta(seconds=1000)\n",
    "            for index, row in self.working_dataframe.iterrows():\n",
    "                # print(type(insert_null_mask[index]))\n",
    "                if insert_null_mask[index].any():\n",
    "                    null_row = pd.Series([np.NaN] * len(self.working_dataframe.columns),\n",
    "                                         index=self.working_dataframe.columns)\n",
    "                    result_rows.append(null_row)\n",
    "                result_rows.append(row)\n",
    "            self.working_dataframe = pd.DataFrame(result_rows)\n",
    "            if not self.working_dataframe.empty:\n",
    "                self.working_dataframe.reset_index(drop=True, inplace=True)\n",
    "                self.working_dataframe.drop(columns=['time_diff'], inplace=True)\n",
    "            elif self.working_dataframe.empty:\n",
    "                self.working_dataframe = self.working_dataframe.copy()\n",
    "        return self.working_dataframe\n",
    "\n",
    "    def handle_repeated_columns(self) -> Union[pd.DataFrame, None]:\n",
    "\n",
    "        column_counts = {}\n",
    "        # new_columns = []\n",
    "        if self.working_dataframe is not None:\n",
    "\n",
    "            for column in self.working_dataframe.columns:\n",
    "                if column in column_counts:\n",
    "\n",
    "                    new_column_name = f\"{column}{column_counts[column]}\"\n",
    "\n",
    "                    if column_counts[column] != 1:\n",
    "                        column_counts[column] = 1\n",
    "                    column_counts[column] += 1\n",
    "                    self.working_dataframe = self.working_dataframe.rename(columns={column: new_column_name})\n",
    "\n",
    "                else:\n",
    "                    column_counts[column] = 1\n",
    "            # print(self.working_dataframe)\n",
    "        return self.working_dataframe\n",
    "\n",
    "\n",
    "def convert_epoch_to_datetime(epoch):\n",
    "    return pd.to_datetime(epoch, unit='ms')\n",
    "\n",
    "\n",
    "timestamp_start_range = convert_epoch_to_datetime(1686594600000)\n",
    "\n",
    "\n",
    "def clean_file(csv_file_path):\n",
    "    file_handler = FileHandlingMethods(csv_file_path, working_dataframe=None)\n",
    "    file_handler.handle_any_file()\n",
    "    file_handler.handle_registers_values()\n",
    "    df = file_handler.handle_repeated_columns()\n",
    "    if df is not None:\n",
    "        df['UTC_Time'] = pd.to_datetime(\n",
    "            np.clip(df['epoch [msec]'], np.iinfo(np.int64).min, np.iinfo(np.int64).max),\n",
    "            unit='ms',\n",
    "            errors='coerce'\n",
    "        )\n",
    "        df = df.sort_values(by='UTC_Time')\n",
    "        timestamp_mask = df['UTC_Time'] < timestamp_start_range\n",
    "        if ~timestamp_mask.any():\n",
    "            df = df[~timestamp_mask]\n",
    "    return df\n",
    "\n",
    "\n",
    "# files_dir = os.path.expanduser('~/static/media/orbit_attitude')\n",
    "# saving_path = os.path.expanduser('~/static/media/orbit_attitude/merged/{{}}.csv')\n",
    "\n",
    "\n",
    "def save_csv(df, col_key, file_saving_path):\n",
    "    if not df.empty:\n",
    "        df = df.sort_values(by='UTC_Time')\n",
    "        df = df.drop_duplicates(subset=['UTC_Time'])\n",
    "        df.to_csv(path_or_buf=file_saving_path.format(col_key), sep=',', index=False)\n",
    "\n",
    "\n",
    "# merged_df.to_csv(saving_path.format('sample_obc'),sep=',', index=False)\n",
    "# print(merged_df)\n",
    "\n",
    "\n",
    "def sanitize_column_name(col_name):\n",
    "    # Replace parentheses () with square brackets []\n",
    "    return col_name.replace('(', '[').replace(')', ']')\n",
    "\n",
    "\n",
    "def sanitize_dataframe_columns(df):\n",
    "    # Create a new DataFrame with sanitized column names\n",
    "    new_columns = [sanitize_column_name(col) for col in df.columns]\n",
    "    return df.rename(columns=dict(zip(df.columns, new_columns)))\n",
    "\n",
    "\n",
    "def get_sql_dtype(col_name, pandas_dtype):\n",
    "    if col_name == 'UTC_Time':\n",
    "        return 'TIMESTAMP PRIMARY KEY'\n",
    "    if pd.api.types.is_integer_dtype(pandas_dtype):\n",
    "        return 'BIGINT'\n",
    "    elif pd.api.types.is_float_dtype(pandas_dtype):\n",
    "        return 'FLOAT'\n",
    "    elif pd.api.types.is_bool_dtype(pandas_dtype):\n",
    "        return 'BOOLEAN'\n",
    "    else:\n",
    "        return 'TEXT'\n",
    "\n",
    "\n",
    "def create_table(cursor, table_name, columns):\n",
    "    column_defs = []\n",
    "    for col_name, dtype in columns.items():\n",
    "        sql_dtype = get_sql_dtype(col_name, dtype)\n",
    "        # col_name = col_name.replace('(', '[').replace(')', ']')\n",
    "        # print(col_name)\n",
    "        column_defs.append(f'\"{col_name}\" {sql_dtype}')\n",
    "    column_defs_str = \", \".join(column_defs)\n",
    "    print(column_defs_str)\n",
    "    create_table_query = f\"CREATE TABLE IF NOT EXISTS {table_name} ({column_defs_str})\"\n",
    "    cursor.execute(create_table_query)\n",
    "    for col_name, dtype in columns.items():\n",
    "        add_column_if_not_exists(cursor, table_name, col_name, dtype)\n",
    "\n",
    "\n",
    "def add_column_if_not_exists(cursor, table_name, col_name, dtype):\n",
    "    sql_dtype = get_sql_dtype(col_name, dtype)\n",
    "\n",
    "    cursor.execute(f\"\"\"\n",
    "        SELECT column_name \n",
    "        FROM information_schema.columns \n",
    "        WHERE table_name='{table_name}' AND column_name='{col_name}'\n",
    "    \"\"\")\n",
    "    if not cursor.fetchone():\n",
    "        alter_table_query = f'ALTER TABLE {table_name} ADD COLUMN \"{col_name}\" {sql_dtype}'\n",
    "        cursor.execute(alter_table_query)\n",
    "\n",
    "\n",
    "def insert_data(cursor, table_name, dataframe):\n",
    "    columns = list(dataframe.columns)\n",
    "    columns_identifiers = [sql.Identifier(col) for col in columns]\n",
    "    values_placeholders = [sql.Placeholder(col) for col in columns]\n",
    "\n",
    "    insert_query = sql.SQL(\"\"\"\n",
    "        INSERT INTO {} ({}) VALUES ({})\n",
    "        ON CONFLICT (\"UTC_Time\") DO NOTHING\n",
    "    \"\"\").format(\n",
    "        sql.Identifier(table_name),\n",
    "        sql.SQL(', ').join(columns_identifiers),\n",
    "        sql.SQL(', ').join(values_placeholders)\n",
    "    )\n",
    "\n",
    "    for _, row in dataframe.iterrows():\n",
    "        cursor.execute(insert_query, row.to_dict())\n",
    "\n",
    "\n",
    "def main(df, table_name, dbname, user, password, host='localhost', port=5432):\n",
    "    df = sanitize_dataframe_columns(df)\n",
    "    if 'UTC_Time' in df.columns:\n",
    "        df['UTC_Time'] = pd.to_datetime(df['UTC_Time'], errors='coerce')\n",
    "\n",
    "    conn = psycopg2.connect(dbname=dbname, user=user, password=password, host=host, port=port)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    try:\n",
    "        create_table(cursor, table_name, df.dtypes.to_dict())\n",
    "\n",
    "        insert_data(cursor, table_name, df)\n",
    "        conn.commit()\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\", table_name)\n",
    "        conn.rollback()\n",
    "    finally:\n",
    "        # Close the connection\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    files_list = {\n",
    "        'ppdh_ltt': glob.glob(files_dir + '/*ppdh_ltt*.csv'),\n",
    "        'obc_ltt': glob.glob(files_dir + '/*obc_ltt*.csv'),\n",
    "        'gps_ltt': glob.glob(files_dir + '/*gps_ltt*.csv'),\n",
    "        'acc_ltt': glob.glob(files_dir + '/*acc_ltt*.csv'),\n",
    "        'acc_ott': glob.glob(files_dir + '/*acc_ott*.csv'),\n",
    "        'pcu_ltt': glob.glob(files_dir + '/*pcu_ltt*.csv')\n",
    "    }\n",
    "\n",
    "    final_dfs = {\n",
    "        'ppdh_ltt': pd.DataFrame(),\n",
    "        'obc_ltt': pd.DataFrame(),\n",
    "        'gps_ltt': pd.DataFrame(),\n",
    "        'acc_ltt': pd.DataFrame(),\n",
    "        'acc_ott': pd.DataFrame(),\n",
    "        'pcu_ltt': pd.DataFrame()\n",
    "    }\n",
    "\n",
    "    for file_type, file_paths in files_list.items():\n",
    "        for file_path in file_paths:\n",
    "            df2 = clean_file(file_path)\n",
    "\n",
    "            if final_dfs[file_type].empty:\n",
    "                final_dfs[file_type] = df2\n",
    "            else:\n",
    "                final_dfs[file_type] = pd.concat([final_dfs[file_type], df2], axis=0, ignore_index=True, sort=False)\n",
    "                final_dfs[file_type] = final_dfs[file_type].drop_duplicates(subset=['UTC_Time'], keep='first')\n",
    "                final_dfs[file_type] = final_dfs[file_type].dropna(axis=1, how='all')\n",
    "\n",
    "                # all_columns = set(final_dfs[file_type].columns).union(set(df2.columns))\n",
    "                # final_dfs[file_type] = final_dfs[file_type].reindex(columns=all_columns)\n",
    "\n",
    "    print('merging complete')\n",
    "\n",
    "    local_conn_1 = psycopg2.connect(\n",
    "        host=\"localhost\",\n",
    "        port=\"5432\",\n",
    "        database=\"web_application_testing\",\n",
    "        user=\"april\",\n",
    "        password=\"u&e!!!s4g3es28iTv3oqvkBod\"\n",
    "    )\n",
    "    cur = local_conn_1.cursor()\n",
    "    # files_dir = os.path.expanduser('~/static/media/orbit_attitude/merged/')\n",
    "    #\n",
    "    # mer_files_list = {\n",
    "    #     'ppdh_ltt': glob.glob(mer_files_dir + '/*ppdh_ltt*.csv'),\n",
    "    #     'obc_ltt': glob.glob(mer_files_dir + '/*obc_ltt*.csv'),\n",
    "    #     'gps_ltt': glob.glob(mer_files_dir + '/*gps_ltt*.csv'),\n",
    "    #     'acc_ltt': glob.glob(mer_files_dir + '/*acc_ltt*.csv'),\n",
    "    #     'acc_ott': glob.glob(mer_files_dir + '/*acc_ott*.csv'),\n",
    "    #     'pcu_ltt': glob.glob(mer_files_dir + '/*pcu_ltt*.csv')\n",
    "    # }\n",
    "    for key, value in final_dfs.items():\n",
    "        if not value.empty:\n",
    "            # print(key, value)\n",
    "            save_csv(value, key, saving_path)\n",
    "            main(\n",
    "                df=value,\n",
    "                table_name=key,\n",
    "                dbname='web_application',\n",
    "                user='april',\n",
    "                password='u&e!!!s4g3es28iTv3oqvkBod',\n",
    "                host='localhost',\n",
    "                port=5432\n",
    "            )\n",
    "            print('pushed files into database, ', key)\n",
    "\n",
    "            # main(\n",
    "            #     csv_path=file_path,\n",
    "            #     table_name=file_type,\n",
    "            #     dbname='web_application',\n",
    "            #     user='april',\n",
    "            #     password='u&e!!!s4g3es28iTv3oqvkBod',\n",
    "            #     host='localhost',\n",
    "            #     port=5432\n",
    "            # )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location values updated successfully.\n"
     ]
    }
   ],
   "source": [
    "import psycopg2    \n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "csvflepath = '/home/pavankoundinya-april/Documents/loc_data.csv'\n",
    "df = pd.read_csv(filepath_or_buffer=csvflepath, delimiter='|')\n",
    "connection = psycopg2.connect(\n",
    "        host=\"localhost\",\n",
    "        port=\"5432\",\n",
    "        database=\"web_application_production\",\n",
    "        user=\"april\",\n",
    "        password=\"u&e!!!s4g3es28iTv3oqvkBod\"\n",
    "    )\n",
    "cursor = connection.cursor()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    \n",
    "    # Iterate through the DataFrame and update the 'location' value based on 'id'\n",
    "    for index, row in df.iterrows():\n",
    "        update_query = \"\"\"\n",
    "        UPDATE images_data\n",
    "        SET location = %s\n",
    "        WHERE id = %s\n",
    "        \"\"\"\n",
    "        cursor.execute(update_query, (row['location'], row['id']))\n",
    "    \n",
    "    # Commit the transaction\n",
    "    connection.commit()\n",
    "\n",
    "    print(\"Location values updated successfully.\")\n",
    "    \n",
    "except Exception as error:\n",
    "    print(f\"Error occurred: {error}\")\n",
    "    \n",
    "finally:\n",
    "    if cursor:\n",
    "        cursor.close()\n",
    "    if connection:\n",
    "        connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Makarba, Ahmedabad, Gujarat, India\n",
      "{'address_descriptor': {'areas': [{'containment': 'WITHIN', 'display_name': {'language_code': 'en', 'text': 'Bhaskar House'}, 'place_id': 'ChIJs91mUNyaXjkRV6rwIqBf2PM'}, {'containment': 'WITHIN', 'display_name': {'language_code': 'en', 'text': 'Makarba'}, 'place_id': 'ChIJo4OYLduaXjkR4YWlcW9mepE'}], 'landmarks': [{'display_name': {'language_code': 'en', 'text': 'Vodafone House'}, 'place_id': 'ChIJVxH19duaXjkR-9TBbAnmPg0', 'spatial_relationship': 'NEAR', 'straight_line_distance_meters': 248.706298828125, 'travel_distance_meters': 517.8432006835938, 'types': ['establishment', 'point_of_interest']}, {'display_name': {'language_code': 'en', 'text': 'Divya Bhaskar Ahmedabad Main Office'}, 'place_id': 'ChIJJURgrd2aXjkRPYh1DQuBLhI', 'spatial_relationship': 'DOWN_THE_ROAD', 'straight_line_distance_meters': 60.5574951171875, 'travel_distance_meters': 394.6375732421875, 'types': ['establishment', 'point_of_interest']}, {'display_name': {'language_code': 'en', 'text': 'HDFC Bank'}, 'place_id': 'ChIJnxMRqt2aXjkRYcR5clO_dyQ', 'spatial_relationship': 'DOWN_THE_ROAD', 'straight_line_distance_meters': 58.17945098876953, 'travel_distance_meters': 98.73141479492188, 'types': ['bank', 'establishment', 'finance', 'point_of_interest']}, {'display_name': {'language_code': 'en', 'text': 'SBI INTOUCH'}, 'place_id': 'ChIJx7NEqt2aXjkRki4CvFmcZ8M', 'spatial_relationship': 'AROUND_THE_CORNER', 'straight_line_distance_meters': 50.54422760009766, 'travel_distance_meters': 71.53549194335938, 'types': ['bank', 'establishment', 'finance', 'point_of_interest']}, {'display_name': {'language_code': 'en', 'text': 'Dev prime Office'}, 'place_id': 'ChIJpyqRf2SbXjkRn3y0nX3-iNE', 'spatial_relationship': 'NEAR', 'straight_line_distance_meters': 168.2368469238281, 'travel_distance_meters': 191.9499664306641, 'types': ['establishment', 'point_of_interest']}]}, 'plus_code': {'compound_code': '2G22+225 Ahmedabad, Gujarat, India', 'global_code': '7JMJ2G22+225'}, 'results': [{'address_components': [{'long_name': '402', 'short_name': '402', 'types': ['street_number']}, {'long_name': 'Sarkhej - Gandhinagar Highway', 'short_name': 'SG Road', 'types': ['route']}, {'long_name': 'Vasna Telephone Exchange', 'short_name': 'Vasna Telephone Exchange', 'types': ['political', 'sublocality', 'sublocality_level_3']}, {'long_name': 'Makarba', 'short_name': 'Makarba', 'types': ['political', 'sublocality', 'sublocality_level_1']}, {'long_name': 'Ahmedabad', 'short_name': 'Ahmedabad', 'types': ['locality', 'political']}, {'long_name': 'Ahmedabad', 'short_name': 'Ahmedabad', 'types': ['administrative_area_level_3', 'political']}, {'long_name': 'Gujarat', 'short_name': 'GJ', 'types': ['administrative_area_level_1', 'political']}, {'long_name': 'India', 'short_name': 'IN', 'types': ['country', 'political']}, {'long_name': '380013', 'short_name': '380013', 'types': ['postal_code']}], 'formatted_address': '402, Sarkhej - Gandhinagar Hwy, Vasna Telephone Exchange, Makarba, Ahmedabad, Gujarat 380013, India', 'geometry': {'location': {'lat': 22.9998883, 'lng': 72.5002689}, 'location_type': 'ROOFTOP', 'viewport': {'northeast': {'lat': 23.0012372802915, 'lng': 72.50161788029149}, 'southwest': {'lat': 22.9985393197085, 'lng': 72.49891991970848}}}, 'place_id': 'ChIJSdxbVtyaXjkRocKggjBkqcc', 'plus_code': {'compound_code': 'XGX2+X4 Ahmedabad, Gujarat, India', 'global_code': '7JJJXGX2+X4'}, 'types': ['street_address']}, {'address_components': [{'long_name': '2G22+22', 'short_name': '2G22+22', 'types': ['plus_code']}, {'long_name': 'Ahmedabad', 'short_name': 'Ahmedabad', 'types': ['locality', 'political']}, {'long_name': 'Ahmedabad', 'short_name': 'Ahmedabad', 'types': ['administrative_area_level_3', 'political']}, {'long_name': 'Gujarat', 'short_name': 'GJ', 'types': ['administrative_area_level_1', 'political']}, {'long_name': 'India', 'short_name': 'IN', 'types': ['country', 'political']}], 'formatted_address': '2G22+22 Ahmedabad, Gujarat, India', 'geometry': {'bounds': {'northeast': {'lat': 23.000125, 'lng': 72.500125}, 'southwest': {'lat': 23, 'lng': 72.5}}, 'location': {'lat': 23, 'lng': 72.5}, 'location_type': 'GEOMETRIC_CENTER', 'viewport': {'northeast': {'lat': 23.0014114802915, 'lng': 72.50141148029151}, 'southwest': {'lat': 22.9987135197085, 'lng': 72.49871351970849}}}, 'place_id': 'GhIJAAAAAAAAN0ARAAAAAAAgUkA', 'plus_code': {'compound_code': '2G22+22 Ahmedabad, Gujarat, India', 'global_code': '7JMJ2G22+22'}, 'types': ['plus_code']}, {'address_components': [{'long_name': 'Unnamed Road', 'short_name': 'Unnamed Road', 'types': ['route']}, {'long_name': 'Makarba', 'short_name': 'Makarba', 'types': ['political', 'sublocality', 'sublocality_level_1']}, {'long_name': 'Ahmedabad', 'short_name': 'Ahmedabad', 'types': ['locality', 'political']}, {'long_name': 'Ahmedabad', 'short_name': 'Ahmedabad', 'types': ['administrative_area_level_3', 'political']}, {'long_name': 'Gujarat', 'short_name': 'GJ', 'types': ['administrative_area_level_1', 'political']}, {'long_name': 'India', 'short_name': 'IN', 'types': ['country', 'political']}, {'long_name': '380015', 'short_name': '380015', 'types': ['postal_code']}], 'formatted_address': 'Unnamed Road, Makarba, Ahmedabad, Gujarat 380015, India', 'geometry': {'bounds': {'northeast': {'lat': 23.0001246, 'lng': 72.49997710000001}, 'southwest': {'lat': 22.9995973, 'lng': 72.4993396}}, 'location': {'lat': 23.0000411, 'lng': 72.4997073}, 'location_type': 'GEOMETRIC_CENTER', 'viewport': {'northeast': {'lat': 23.0012099302915, 'lng': 72.50100733029151}, 'southwest': {'lat': 22.9985119697085, 'lng': 72.49830936970851}}}, 'place_id': 'ChIJgw3gqt2aXjkRoNl54190yj0', 'types': ['route']}, {'address_components': [{'long_name': 'Makarba', 'short_name': 'Makarba', 'types': ['political', 'sublocality', 'sublocality_level_1']}, {'long_name': 'Ahmedabad', 'short_name': 'Ahmedabad', 'types': ['locality', 'political']}, {'long_name': 'Ahmedabad', 'short_name': 'Ahmedabad', 'types': ['administrative_area_level_3', 'political']}, {'long_name': 'Gujarat', 'short_name': 'GJ', 'types': ['administrative_area_level_1', 'political']}, {'long_name': 'India', 'short_name': 'IN', 'types': ['country', 'political']}], 'formatted_address': 'Makarba, Ahmedabad, Gujarat, India', 'geometry': {'bounds': {'northeast': {'lat': 23.00831, 'lng': 72.5152596}, 'southwest': {'lat': 22.986758, 'lng': 72.481948}}, 'location': {'lat': 22.9970087, 'lng': 72.4981173}, 'location_type': 'APPROXIMATE', 'viewport': {'northeast': {'lat': 23.00831, 'lng': 72.5152596}, 'southwest': {'lat': 22.986758, 'lng': 72.481948}}}, 'place_id': 'ChIJo4OYLduaXjkR4YWlcW9mepE', 'types': ['political', 'sublocality', 'sublocality_level_1']}, {'address_components': [{'long_name': '380015', 'short_name': '380015', 'types': ['postal_code']}, {'long_name': 'Ahmedabad', 'short_name': 'Ahmedabad', 'types': ['locality', 'political']}, {'long_name': 'Ahmedabad', 'short_name': 'Ahmedabad', 'types': ['administrative_area_level_3', 'political']}, {'long_name': 'Gujarat', 'short_name': 'GJ', 'types': ['administrative_area_level_1', 'political']}, {'long_name': 'India', 'short_name': 'IN', 'types': ['country', 'political']}], 'formatted_address': 'Ahmedabad, Gujarat 380015, India', 'geometry': {'bounds': {'northeast': {'lat': 23.0416362, 'lng': 72.5504713}, 'southwest': {'lat': 22.9983736, 'lng': 72.4986559}}, 'location': {'lat': 23.024349, 'lng': 72.5301521}, 'location_type': 'APPROXIMATE', 'viewport': {'northeast': {'lat': 23.0416362, 'lng': 72.5504713}, 'southwest': {'lat': 22.9983736, 'lng': 72.4986559}}}, 'place_id': 'ChIJIQ-JS9KEXjkRqz88KwBtNEE', 'types': ['postal_code']}, {'address_components': [{'long_name': 'Ahmadabad', 'short_name': 'Ahmadabad', 'types': ['administrative_area_level_4', 'political']}, {'long_name': 'Ahmedabad', 'short_name': 'Ahmedabad', 'types': ['administrative_area_level_3', 'political']}, {'long_name': 'Gujarat', 'short_name': 'GJ', 'types': ['administrative_area_level_1', 'political']}, {'long_name': 'India', 'short_name': 'IN', 'types': ['country', 'political']}], 'formatted_address': 'Ahmadabad, Gujarat, India', 'geometry': {'bounds': {'northeast': {'lat': 23.1386502, 'lng': 72.6868834}, 'southwest': {'lat': 22.9340398, 'lng': 72.4651094}}, 'location': {'lat': 23.0224859, 'lng': 72.5713667}, 'location_type': 'APPROXIMATE', 'viewport': {'northeast': {'lat': 23.1386502, 'lng': 72.6868834}, 'southwest': {'lat': 22.9340398, 'lng': 72.4651094}}}, 'place_id': 'ChIJb_mkWlyEXjkRR3D6kLFX_zc', 'types': ['administrative_area_level_4', 'political']}, {'address_components': [{'long_name': 'Ahmedabad', 'short_name': 'Ahmedabad', 'types': ['locality', 'political']}, {'long_name': 'Ahmedabad', 'short_name': 'Ahmedabad', 'types': ['administrative_area_level_3', 'political']}, {'long_name': 'Gujarat', 'short_name': 'GJ', 'types': ['administrative_area_level_1', 'political']}, {'long_name': 'India', 'short_name': 'IN', 'types': ['country', 'political']}], 'formatted_address': 'Ahmedabad, Gujarat, India', 'geometry': {'bounds': {'northeast': {'lat': 23.1378156, 'lng': 72.7053737}, 'southwest': {'lat': 22.902676, 'lng': 72.4534827}}, 'location': {'lat': 23.022505, 'lng': 72.5713621}, 'location_type': 'APPROXIMATE', 'viewport': {'northeast': {'lat': 23.1378156, 'lng': 72.7053737}, 'southwest': {'lat': 22.902676, 'lng': 72.4534827}}}, 'place_id': 'ChIJSdRbuoqEXjkRFmVPYRHdzk8', 'types': ['locality', 'political']}, {'address_components': [{'long_name': 'Ahmedabad', 'short_name': 'Ahmedabad', 'types': ['administrative_area_level_3', 'political']}, {'long_name': 'Gujarat', 'short_name': 'GJ', 'types': ['administrative_area_level_1', 'political']}, {'long_name': 'India', 'short_name': 'IN', 'types': ['country', 'political']}], 'formatted_address': 'Ahmedabad, Gujarat, India', 'geometry': {'bounds': {'northeast': {'lat': 23.508784, 'lng': 72.8426217}, 'southwest': {'lat': 21.970603, 'lng': 71.8399848}}, 'location': {'lat': 23.0225133, 'lng': 72.57136919999999}, 'location_type': 'APPROXIMATE', 'viewport': {'northeast': {'lat': 23.508784, 'lng': 72.8426217}, 'southwest': {'lat': 21.970603, 'lng': 71.8399848}}}, 'place_id': 'ChIJIxcnN0CEXjkRobQIMyNYLpI', 'types': ['administrative_area_level_3', 'political']}, {'address_components': [{'long_name': 'Gujarat', 'short_name': 'GJ', 'types': ['administrative_area_level_1', 'political']}, {'long_name': 'India', 'short_name': 'IN', 'types': ['country', 'political']}], 'formatted_address': 'Gujarat, India', 'geometry': {'bounds': {'northeast': {'lat': 24.7125362, 'lng': 74.4764324}, 'southwest': {'lat': 20.1192287, 'lng': 68.17751179999999}}, 'location': {'lat': 22.6708317, 'lng': 71.5723953}, 'location_type': 'APPROXIMATE', 'viewport': {'northeast': {'lat': 24.7125362, 'lng': 74.4764324}, 'southwest': {'lat': 20.1192287, 'lng': 68.17751179999999}}}, 'place_id': 'ChIJlfcOXx8FWTkRLlJU7YfYG4Y', 'types': ['administrative_area_level_1', 'political']}, {'address_components': [{'long_name': 'India', 'short_name': 'IN', 'types': ['country', 'political']}], 'formatted_address': 'India', 'geometry': {'bounds': {'northeast': {'lat': 35.6733149, 'lng': 97.39535869999999}, 'southwest': {'lat': 6.4626999, 'lng': 68.1097}}, 'location': {'lat': 20.593684, 'lng': 78.96288}, 'location_type': 'APPROXIMATE', 'viewport': {'northeast': {'lat': 35.6733149, 'lng': 97.39535869999999}, 'southwest': {'lat': 6.4626999, 'lng': 68.1097}}}, 'place_id': 'ChIJkbeSa_BfYzARphNChaFPjNc', 'types': ['country', 'political']}], 'status': 'OK'}\n"
     ]
    }
   ],
   "source": [
    "import googlemaps\n",
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "gmaps = googlemaps.Client(key='AIzaSyBeWp3W4ybtiYG5kVzEcf1MlsHnzsbon-Y')\n",
    "\n",
    "\n",
    "\n",
    "# address_descriptor_result = gmaps.reverse_geocode((40.714224, -73.961452), enable_address_descriptor=True)\n",
    "# address_descriptor_result = 'https://maps.googleapis.com/maps/api/geocode/json?latlng=23,72.5&extra_computations=ADDRESS_DESCRIPTORS&key=AIzaSyBeWp3W4ybtiYG5kVzEcf1MlsHnzsbon-Y'\n",
    "address_descriptor_result = 'https://maps.googleapis.com/maps/api/geocode/json?latlng=23,72.5&location_type=APPROXIMATE&result_type=street_address&key=AIzaSyBeWp3W4ybtiYG5kVzEcf1MlsHnzsbon-Y'\n",
    "response = requests.get(address_descriptor_result)\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    if 'results' in data and len(data['results']) > 0:\n",
    "        components = data['results'][0]['address_components']\n",
    "        address_parts = {\n",
    "            'sublocality': '',\n",
    "            'locality': '',\n",
    "            'administrative_area': '',\n",
    "            'country': ''\n",
    "        }\n",
    "\n",
    "        for component in components:\n",
    "            if 'sublocality' in component['types']:\n",
    "                address_parts['sublocality'] = component['long_name']\n",
    "            elif 'locality' in component['types']:\n",
    "                address_parts['locality'] = component['long_name']\n",
    "            elif 'administrative_area_level_1' in component['types']:\n",
    "                address_parts['administrative_area'] = component['long_name']\n",
    "            elif 'country' in component['types']:\n",
    "                address_parts['country'] = component['long_name']\n",
    "\n",
    "        print(', '.join([value for value in address_parts.values() if value not in address_parts]))\n",
    "    else:\n",
    "        print(\"No address found\")\n",
    "else:\n",
    "    print( f\"Error: {response.status_code}\")\n",
    "print(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2024, 10, 22, 0, 0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "a = datetime.datetime(2024, 10, 22, 0, 0)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
